{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617679e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")\n",
    "\n",
    "include(\"../src/MyDiffMLP.jl\")\n",
    "using .MyDiffMLP\n",
    "const AD = MyDiffMLP.MyAD\n",
    "const NN = MyDiffMLP.MyNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2, Statistics\n",
    "X_train = load(\"../data/imdb_dataset_prepared.jld2\", \"X_train\")\n",
    "y_train = load(\"../data/imdb_dataset_prepared.jld2\", \"y_train\")\n",
    "X_test = load(\"../data/imdb_dataset_prepared.jld2\", \"X_test\")\n",
    "y_test = load(\"../data/imdb_dataset_prepared.jld2\", \"y_test\")\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702c5190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bbbed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN.Chain(\n",
    "    NN.Dense(size(X_train, 1), 32, AD.relu),\n",
    "    NN.Dense(32, 1, AD.sigmoid)\n",
    ")\n",
    "\n",
    "loss(ŷ, y) = begin\n",
    "    ϵ = 1e-7\n",
    "    ŷ = clamp.(ŷ, ϵ, 1 - ϵ)\n",
    "    -mean(y .* log.(ŷ) .+ (1 .- y) .* log.(1 .- ŷ))\n",
    "end\n",
    "\n",
    "accuracy(ŷ, y) = mean((ŷ .> 0.5) .== (y .> 0.5))\n",
    "\n",
    "η = 0.1\n",
    "epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random, Printf\n",
    "function train!(model, X_train, y_train, X_test, y_test)\n",
    "    n = size(X_train, 2)\n",
    "    for epoch in 1:epochs\n",
    "        idx = randperm(n)\n",
    "        total_loss = 0.0\n",
    "        total_acc = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        t = @elapsed begin\n",
    "            for i in 1:batch_size:n\n",
    "                last = min(i + batch_size - 1, n)\n",
    "                x_batch = X_train[:, idx[i:last]]\n",
    "                y_batch = y_train[:, idx[i:last]]\n",
    "\n",
    "                x_var = AD.Variable(x_batch, zeros(size(x_batch)))\n",
    "                output = model(x_var)\n",
    "                nodes = AD.topological_sort(output)\n",
    "                AD.forward!(nodes)\n",
    "\n",
    "                ŷ = output.output\n",
    "                total_loss += loss(ŷ, y_batch)\n",
    "                total_acc += accuracy(ŷ, y_batch)\n",
    "                num_batches += 1\n",
    "\n",
    "                grad_seed = (ŷ .- y_batch) ./ size(y_batch, 2)\n",
    "                AD.backward!(nodes, grad_seed)\n",
    "                NN.update!(NN.parameters(model), η)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        test_var = AD.Variable(X_test, zeros(size(X_test)))\n",
    "        test_output = model(test_var)\n",
    "        AD.forward!(AD.topological_sort(test_output))\n",
    "        y_test_pred = test_output.output\n",
    "\n",
    "        test_loss = loss(y_test_pred, y_test)\n",
    "        test_acc = accuracy(y_test_pred, y_test)\n",
    "\n",
    "        println(@sprintf(\"Epoch: %d (%.2fs) \\tTrain: (l: %.4f, a: %.4f) \\tTest: (l: %.4f, a: %.4f)\",\n",
    "            epoch, t, total_loss / num_batches, total_acc / num_batches, test_loss, test_acc))\n",
    "    end\n",
    "end\n",
    "\n",
    "train!(model, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
