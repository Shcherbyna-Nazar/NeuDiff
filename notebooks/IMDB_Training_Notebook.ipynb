{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b32ec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `e:\\Proga\\AWID\\MyDiffMLP`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0cc822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module MyAD.\n",
      "WARNING: replacing module MyNN.\n",
      "WARNING: using MyAD.GraphNode in module Main conflicts with an existing identifier.\n",
      "WARNING: using MyAD.Variable in module Main conflicts with an existing identifier.\n",
      "WARNING: using MyAD.forward! in module Main conflicts with an existing identifier.\n",
      "WARNING: using MyAD.backward! in module Main conflicts with an existing identifier.\n",
      "WARNING: using MyAD.topological_sort in module Main conflicts with an existing identifier.\n",
      "WARNING: using MyAD.relu in module Main conflicts with an existing identifier.\n",
      "WARNING: using MyAD.sigmoid in module Main conflicts with an existing identifier.\n",
      "WARNING: using MyNN.Dense in module Main conflicts with an existing identifier.\n",
      "WARNING: using MyNN.Chain in module Main conflicts with an existing identifier.\n",
      "WARNING: using MyNN.parameters in module Main conflicts with an existing identifier.\n",
      "WARNING: using MyNN.zero_gradients! in module Main conflicts with an existing identifier.\n",
      "WARNING: using MyNN.AdamState in module Main conflicts with an existing identifier.\n",
      "WARNING: using MyNN.update_adam! in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "include(\"../src/MyAD.jl\")\n",
    "include(\"../src/MyNN.jl\")\n",
    "\n",
    "using ..MyAD\n",
    "using ..MyNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64f8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2\n",
    "X_train = load(\"../data/imdb_dataset_prepared.jld2\", \"X_train\")\n",
    "y_train = load(\"../data/imdb_dataset_prepared.jld2\", \"y_train\")\n",
    "X_test = load(\"../data/imdb_dataset_prepared.jld2\", \"X_test\")\n",
    "y_test = load(\"../data/imdb_dataset_prepared.jld2\", \"y_test\")\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d1a0097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Przykładowe predykcje: [0.5027, 0.4975, 0.5016, 0.504, 0.5096, 0.5022, 0.4999, 0.4952, 0.5019, 0.4952]\n",
      "mean(abs.((params[1]).output)) = 0.008474599055325627\n",
      "maximum(abs.((params[1]).gradient)) = 0.01316483786382292\n",
      "Epoch: 1 (6.51s) \tTrain: (l: 0.57, a: 0.81) \tTest: (l: 0.47, a: 0.86)\n",
      "Epoch: 2 (5.28s) \tTrain: (l: 0.33, a: 0.93) \tTest: (l: 0.37, a: 0.87)\n",
      "Epoch: 3 (5.02s) \tTrain: (l: 0.21, a: 0.96) \tTest: (l: 0.33, a: 0.87)\n",
      "Epoch: 4 (5.22s) \tTrain: (l: 0.14, a: 0.98) \tTest: (l: 0.32, a: 0.87)\n",
      "Epoch: 5 (5.23s) \tTrain: (l: 0.10, a: 0.99) \tTest: (l: 0.31, a: 0.87)\n"
     ]
    }
   ],
   "source": [
    "using  Printf, Statistics, Random\n",
    "\n",
    "\n",
    "function create_batches(X, Y; batchsize=64, shuffle=true)\n",
    "    idxs = collect(1:size(X, 2))\n",
    "    if shuffle\n",
    "        Random.shuffle!(idxs)\n",
    "    end\n",
    "    return [(X[:, idxs[i:min(i+batchsize-1, end)]],\n",
    "             Y[:, idxs[i:min(i+batchsize-1, end)]])\n",
    "             for i in 1:batchsize:length(idxs)]\n",
    "end\n",
    "\n",
    "model = Chain(\n",
    "    Dense(size(X_train, 1), 32, relu),\n",
    "    Dense(32, 1, sigmoid)\n",
    ")\n",
    "\n",
    "function bce(ŷ, y)\n",
    "    ϵ = 1e-7\n",
    "    ŷ_clipped = clamp.(ŷ, ϵ, 1 .- ϵ)\n",
    "    return -mean(y .* log.(ŷ_clipped) .+ (1 .- y) .* log.(1 .- ŷ_clipped))\n",
    "end\n",
    "\n",
    "function bce_grad(ŷ, y)\n",
    "    ϵ = 1e-7\n",
    "    return (ŷ .- y) ./ (clamp.(ŷ .* (1 .- ŷ), ϵ, 1.0)) ./ size(y, 2)\n",
    "end\n",
    "\n",
    "accuracy(ŷ, y) = mean((ŷ .> 0.5) .== (y .> 0.5))\n",
    "\n",
    "epochs = 5\n",
    "batchsize = 64\n",
    "η = 0.001  # typowa wartość dla Adam\n",
    "\n",
    "params = parameters(model)\n",
    "state = AdamState(params)\n",
    "\n",
    "for epoch in 1:epochs\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    batches = create_batches(X_train, y_train; batchsize=batchsize)\n",
    "\n",
    "    t = @elapsed begin\n",
    "        for (x, y) in batches\n",
    "            x_node = Variable(x, zeros(size(x)))\n",
    "            y_node = Variable(y, zeros(size(y)))\n",
    "\n",
    "            out = model(x_node)\n",
    "            graph = topological_sort(out)\n",
    "            forward!(graph)\n",
    "\n",
    "            ŷ = out.output\n",
    "            l = bce(ŷ, y)\n",
    "            total_loss += l\n",
    "            total_acc += accuracy(ŷ, y)\n",
    "            num_batches += 1\n",
    "\n",
    "            out.gradient = bce_grad(ŷ, y)\n",
    "\n",
    "            zero_gradients!(model)\n",
    "            backward!(graph, out.gradient)\n",
    "            update_adam!(state, params, η)\n",
    "\n",
    "            if epoch == 1 && num_batches == 1\n",
    "                println(\"🔍 Przykładowe predykcje: \", round.(ŷ[1, 1:10]; digits=4))\n",
    "                @show mean(abs.(params[1].output))\n",
    "                @show maximum(abs.(params[1].gradient))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    train_loss = total_loss / num_batches\n",
    "    train_acc = total_acc / num_batches\n",
    "\n",
    "    # --- Ewaluacja ---\n",
    "    x_eval = Variable(X_test, zeros(size(X_test)))\n",
    "    out_eval = model(x_eval)\n",
    "    forward!(topological_sort(out_eval))\n",
    "    test_pred = out_eval.output\n",
    "    test_loss = bce(test_pred, y_test)\n",
    "    test_acc = accuracy(test_pred, y_test)\n",
    "\n",
    "    println(@sprintf(\"Epoch: %d (%.2fs) \\tTrain: (l: %.2f, a: %.2f) \\tTest: (l: %.2f, a: %.2f)\",\n",
    "        epoch, t, train_loss, train_acc, test_loss, test_acc))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
